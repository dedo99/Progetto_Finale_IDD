{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFGRMNKpKaTn"
      },
      "source": [
        "# CONTROLLO MATCHING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4aoYVBpTRL0Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from valentine import valentine_match, valentine_metrics\n",
        "from valentine.algorithms import Coma, DistributionBased, Cupid\n",
        "import pprint\n",
        "import numpy as np\n",
        "\n",
        "def list2string(x):\n",
        "    result = ''\n",
        "    if(isinstance(x, list)):\n",
        "        for element in x:\n",
        "            result = result + ', ' + element\n",
        "            return result[1:]\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "# Load data using pandas\n",
        "df1 = pd.read_json(\"schema_mediato_confronto.json\")\n",
        "# df2 = pd.read_json(\"datasets/output_globaldata.json\")\n",
        "df2 = pd.read_json(\"datasets/valueToday_dataset.jsonl\", lines=True)\n",
        "df2 = df2.apply(np.vectorize(list2string))\n",
        "\n",
        "# Instantiate matcher and run\n",
        "# Coma requires java to be installed on your machine\n",
        "# If java is not an option, all the other algorithms are in Python (e.g., Cupid)\n",
        "# matcher = Coma(strategy=\"COMA_OPT\")\n",
        "matcher = DistributionBased(0.9, 0.9)\n",
        "matches = valentine_match(df1, df2, matcher)\n",
        "# print(type(matches))\n",
        "# print(matches)\n",
        "pp = pprint.PrettyPrinter(indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aijlg1l0SPB5",
        "outputId": "ddec83c9-98c8-44d5-f3e8-4bedb71d225a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{(('table_1', 'headquarters'), ('table_2', 'headquarters_region_city')): 0.918299407988494, (('table_1', 'website'), ('table_2', 'company_website')): 0.9141177743412015, (('table_1', 'name'), ('table_2', 'name')): 0.8835215044000037, (('table_1', 'country'), ('table_2', 'headquarters_country')): 0.8697265607735573, (('table_1', 'sector'), ('table_2', 'company_business')): 0.824344321652341, (('table_1', 'area_served'), ('table_2', 'headquarters_continent')): 0.7433102081268582, (('table_1', 'employees'), ('table_2', 'world_rank')): 0.7027325996082138, (('table_1', 'employees'), ('table_2', 'number_of_employees')): 0.7022677228450745}\n"
          ]
        }
      ],
      "source": [
        "pp.pprint(matches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3P9_rE8KlsE"
      },
      "source": [
        "# CREAZIONE SCHEMA MEDIATO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1tps-iRnX8BP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from valentine import valentine_match, valentine_metrics\n",
        "from valentine.algorithms import Coma, DistributionBased\n",
        "import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "crg_rQglUSIn"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------------------------\n",
        "# CREATA PER INIZIALIZZARE UN DATASET FITTIZIO MA ORA NON\n",
        "# SI UTILIZZA IL DATASET FITTIZIO DA NOI CREATO MANUALMENTE\n",
        "# ---------------------------------------------------------\n",
        "def creation_dataset_confronto(df1):\n",
        "  # Load data using pandas\n",
        "  df2 = pd.read_json(\"datasets/output_disfold.json\")\n",
        "\n",
        "  matcher_coma = Coma(strategy=\"COMA_OPT\")\n",
        "  matches_coma = valentine_match(df1, df2, matcher_coma)\n",
        "\n",
        "  attributi_mediato = []\n",
        "  attributi_dataset = []\n",
        "  for i in matches_coma:\n",
        "    if matches_coma[i] > 0.5:\n",
        "      attributi_mediato.append(i[0][1])\n",
        "      attributi_dataset.append(i[1][1])\n",
        "\n",
        "  for i in df2.index:\n",
        "      data = {}\n",
        "      # print(i)\n",
        "      for d,m in zip(attributi_dataset,attributi_mediato):\n",
        "        # print(df2[d][i])\n",
        "        data[m] = df2[d][i]\n",
        "      temp_data=pd.DataFrame([data])\n",
        "      df1=pd.concat([df1, temp_data], ignore_index=True)\n",
        "\n",
        "  return df1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DVedhsAfTd4Q"
      },
      "outputs": [],
      "source": [
        "def creation_df_log_matcher(df_logmachers, matches, i, type, name_dataset):\n",
        "  record = {}\n",
        "  record['tab1'] = i[0][0]\n",
        "  record['attr1'] = i[0][1]\n",
        "  record['tab2'] = name_dataset\n",
        "  record['attr2'] = i[1][1]\n",
        "  record['prob'] = matches[i]\n",
        "  if type == 'coma':\n",
        "    record['matcher'] = 'Coma'\n",
        "  else:\n",
        "    record['matcher'] = 'DistributionBased'\n",
        "  temp_record=pd.DataFrame([record])\n",
        "  # df_logmachers=df_logmachers.append(record, ignore_index=True)\n",
        "  df_logmachers=pd.concat([df_logmachers, temp_record], ignore_index=True)\n",
        "  return df_logmachers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "p4Lergf02gnb"
      },
      "outputs": [],
      "source": [
        "def creation_schema_alignment(df1, df2, df_confronto, df_logmachers, name_dataset):\n",
        "\n",
        "  # Instantiate matcher and run\n",
        "  # Coma requires java to be installed on your machine\n",
        "  # If java is not an option, all the other algorithms are in Python (e.g., Cupid)\n",
        "  matcher_coma = Coma(strategy=\"COMA_OPT\")\n",
        "  matches_coma = valentine_match(df1, df2, matcher_coma)\n",
        "\n",
        "  distr_run = False\n",
        "\n",
        " \n",
        "  attributi_mediato = []\n",
        "  attributi_dataset = []\n",
        "  for i in matches_coma:\n",
        "    df_logmachers = creation_df_log_matcher(df_logmachers, matches_coma, i, 'coma', name_dataset)\n",
        "    if matches_coma[i] > 0.5:\n",
        "      attributi_mediato.append(i[0][1])\n",
        "      attributi_dataset.append(i[1][1])\n",
        "    else:\n",
        "      try:\n",
        "        if not distr_run:\n",
        "          matcher_distr = DistributionBased(0.9, 0.9)\n",
        "          matches_distr = valentine_match(df_confronto, df2, matcher_distr)\n",
        "          distr_run = True\n",
        "        # distribution based giÃ  instanziato\n",
        "        df_logmachers = creation_df_log_matcher(df_logmachers, matches_distr, i, 'distribution', name_dataset)\n",
        "        if matches_distr[i] > 0.5:\n",
        "          attributi_mediato.append(i[0][1])\n",
        "          attributi_dataset.append(i[1][1])\n",
        "      except:\n",
        "        pass\n",
        "  # print(attributi_dataset)\n",
        "  # print(attributi_mediato)\n",
        "\n",
        "  # inserimento dei dati nel dataframe\n",
        "  for i in df2.index:\n",
        "    data = {}\n",
        "    # print(i)\n",
        "    for d,m in zip(attributi_dataset,attributi_mediato):\n",
        "      # print(df2[d][i])\n",
        "      data[m] = df2[d][i]\n",
        "    temp_data=pd.DataFrame([data])\n",
        "    df1=pd.concat([df1, temp_data], ignore_index=True)\n",
        "\n",
        "  pp = pprint.PrettyPrinter(indent=4)\n",
        "\n",
        "  # stampa dei matchers\n",
        "  pp.pprint(matches_coma)\n",
        "  if distr_run:\n",
        "    pp.pprint(matches_distr)\n",
        "\n",
        "  return df1, df_logmachers\n",
        "  # print(df1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y-wil64YB-gE",
        "outputId": "c6480d8f-0567-4960-e8f1-c3caa5b576e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 datasets\\companiesMarketCap_dataset.jsonl\n",
            "companiesMarketCap_dataset.jsonl\n",
            "unhashable type: 'list'\n",
            "ERRORE datasets\\companiesMarketCap_dataset.jsonl\n",
            "1 datasets\\disfold_dataset.jsonl\n",
            "disfold_dataset.jsonl\n",
            "{   (('table_1', 'ceo'), ('table_2', 'ceo')): 0.8310757,\n",
            "    (('table_1', 'employees'), ('table_2', 'employees')): 0.84929436,\n",
            "    (('table_1', 'founded'), ('table_2', 'founded')): 0.8446504,\n",
            "    (('table_1', 'headquarters'), ('table_2', 'headquarters_country')): 0.6355629,\n",
            "    (('table_1', 'market_cap'), ('table_2', 'market_cap')): 0.851268,\n",
            "    (('table_1', 'name'), ('table_2', 'name')): 0.83519655}\n",
            "2 datasets\\hitHorizons_dataset.jsonl\n",
            "hitHorizons_dataset.jsonl\n",
            "{   (('table_1', 'address'), ('table_2', 'address')): 0.797828,\n",
            "    (('table_1', 'earnings'), ('table_2', 'sic_code')): 0.275279,\n",
            "    (('table_1', 'founded'), ('table_2', 'id')): 0.29596865,\n",
            "    (('table_1', 'industry'), ('table_2', 'industry')): 0.80027896,\n",
            "    (('table_1', 'name'), ('table_2', 'name')): 0.7883742}\n",
            "{}\n",
            "3 datasets\\valueToday_dataset.jsonl\n",
            "valueToday_dataset.jsonl\n",
            "unhashable type: 'list'\n",
            "ERRORE datasets\\valueToday_dataset.jsonl\n",
            "Numero errori: 2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>industry</th>\n",
              "      <th>market_cap</th>\n",
              "      <th>employees</th>\n",
              "      <th>country</th>\n",
              "      <th>headquarters</th>\n",
              "      <th>address</th>\n",
              "      <th>sector</th>\n",
              "      <th>ceo</th>\n",
              "      <th>founded</th>\n",
              "      <th>share_price</th>\n",
              "      <th>website</th>\n",
              "      <th>stock</th>\n",
              "      <th>area_served</th>\n",
              "      <th>earnings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Apple</td>\n",
              "      <td>NaN</td>\n",
              "      <td>$2.825 Trillion</td>\n",
              "      <td>100,000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Cupertino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mr. Timothy D. Cook</td>\n",
              "      <td>April 1, 1976</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Danaher</td>\n",
              "      <td>NaN</td>\n",
              "      <td>$208.03 Billion</td>\n",
              "      <td>78,000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Washington</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mr. Rainer M. Blair</td>\n",
              "      <td>1969</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Merck</td>\n",
              "      <td>NaN</td>\n",
              "      <td>$210.38 Billion</td>\n",
              "      <td>67,000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Kenilworth</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mr. Robert M. Davis J.D.</td>\n",
              "      <td>1891</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bhp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A$281.66 Billion</td>\n",
              "      <td>40,110</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Melbourne</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mr. Mike P. Henry B.Sc., BSc (Chem)</td>\n",
              "      <td>1885</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nike</td>\n",
              "      <td>NaN</td>\n",
              "      <td>$213.60 Billion</td>\n",
              "      <td>73,300</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Beaverton</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mr. John J. Donahoe II</td>\n",
              "      <td>January 25, 1964</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1662</th>\n",
              "      <td>Legacy Srl</td>\n",
              "      <td>Finance, Insurance, and Real Estate</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>VIA DELLA ZECCA 2, BOLOGNA, 40121, BOLOGNA, ITALY</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1663</th>\n",
              "      <td>Cribis Holding Srl</td>\n",
              "      <td>Finance, Insurance, and Real Estate</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>VIA DELLA ZECCA 2, BOLOGNA, 40121, BOLOGNA, ITALY</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1664</th>\n",
              "      <td>Porsche Italia Spa</td>\n",
              "      <td>Retail Trade</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CORSO STATI UNITI 35, PADOVA, 35127, PADOVA, I...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1665</th>\n",
              "      <td>Intesa Sanpaolo Rbm Salute Spa</td>\n",
              "      <td>Finance, Insurance, and Real Estate</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>VIALE STELVIO 55/57, MILANO, 20159, MILANO, ITALY</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1666</th>\n",
              "      <td>Brenntag Spa</td>\n",
              "      <td>Wholesale Trade</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>STRADA 6 PALAZZO A 13 MILANOFIORI 0SNC, ASSAGO...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1667 rows Ã 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                name                             industry  \\\n",
              "0                              Apple                                  NaN   \n",
              "1                            Danaher                                  NaN   \n",
              "2                              Merck                                  NaN   \n",
              "3                                Bhp                                  NaN   \n",
              "4                               Nike                                  NaN   \n",
              "...                              ...                                  ...   \n",
              "1662                      Legacy Srl  Finance, Insurance, and Real Estate   \n",
              "1663              Cribis Holding Srl  Finance, Insurance, and Real Estate   \n",
              "1664              Porsche Italia Spa                         Retail Trade   \n",
              "1665  Intesa Sanpaolo Rbm Salute Spa  Finance, Insurance, and Real Estate   \n",
              "1666                    Brenntag Spa                      Wholesale Trade   \n",
              "\n",
              "            market_cap employees country headquarters  \\\n",
              "0      $2.825 Trillion   100,000     NaN    Cupertino   \n",
              "1      $208.03 Billion    78,000     NaN   Washington   \n",
              "2      $210.38 Billion    67,000     NaN   Kenilworth   \n",
              "3     A$281.66 Billion    40,110     NaN    Melbourne   \n",
              "4      $213.60 Billion    73,300     NaN    Beaverton   \n",
              "...                ...       ...     ...          ...   \n",
              "1662               NaN       NaN     NaN          NaN   \n",
              "1663               NaN       NaN     NaN          NaN   \n",
              "1664               NaN       NaN     NaN          NaN   \n",
              "1665               NaN       NaN     NaN          NaN   \n",
              "1666               NaN       NaN     NaN          NaN   \n",
              "\n",
              "                                                address sector  \\\n",
              "0                                                   NaN    NaN   \n",
              "1                                                   NaN    NaN   \n",
              "2                                                   NaN    NaN   \n",
              "3                                                   NaN    NaN   \n",
              "4                                                   NaN    NaN   \n",
              "...                                                 ...    ...   \n",
              "1662  VIA DELLA ZECCA 2, BOLOGNA, 40121, BOLOGNA, ITALY    NaN   \n",
              "1663  VIA DELLA ZECCA 2, BOLOGNA, 40121, BOLOGNA, ITALY    NaN   \n",
              "1664  CORSO STATI UNITI 35, PADOVA, 35127, PADOVA, I...    NaN   \n",
              "1665  VIALE STELVIO 55/57, MILANO, 20159, MILANO, ITALY    NaN   \n",
              "1666  STRADA 6 PALAZZO A 13 MILANOFIORI 0SNC, ASSAGO...    NaN   \n",
              "\n",
              "                                      ceo           founded share_price  \\\n",
              "0                     Mr. Timothy D. Cook     April 1, 1976         NaN   \n",
              "1                     Mr. Rainer M. Blair              1969         NaN   \n",
              "2                Mr. Robert M. Davis J.D.              1891         NaN   \n",
              "3     Mr. Mike P. Henry B.Sc., BSc (Chem)              1885         NaN   \n",
              "4                  Mr. John J. Donahoe II  January 25, 1964         NaN   \n",
              "...                                   ...               ...         ...   \n",
              "1662                                  NaN               NaN         NaN   \n",
              "1663                                  NaN               NaN         NaN   \n",
              "1664                                  NaN               NaN         NaN   \n",
              "1665                                  NaN               NaN         NaN   \n",
              "1666                                  NaN               NaN         NaN   \n",
              "\n",
              "     website stock area_served earnings  \n",
              "0        NaN   NaN         NaN      NaN  \n",
              "1        NaN   NaN         NaN      NaN  \n",
              "2        NaN   NaN         NaN      NaN  \n",
              "3        NaN   NaN         NaN      NaN  \n",
              "4        NaN   NaN         NaN      NaN  \n",
              "...      ...   ...         ...      ...  \n",
              "1662     NaN   NaN         NaN      NaN  \n",
              "1663     NaN   NaN         NaN      NaN  \n",
              "1664     NaN   NaN         NaN      NaN  \n",
              "1665     NaN   NaN         NaN      NaN  \n",
              "1666     NaN   NaN         NaN      NaN  \n",
              "\n",
              "[1667 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------DATAFRAME LOG MATCHERS--------\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tab1</th>\n",
              "      <th>attr1</th>\n",
              "      <th>tab2</th>\n",
              "      <th>attr2</th>\n",
              "      <th>prob</th>\n",
              "      <th>matcher</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>table_1</td>\n",
              "      <td>market_cap</td>\n",
              "      <td>disfold_dataset.jsonl</td>\n",
              "      <td>market_cap</td>\n",
              "      <td>0.851268</td>\n",
              "      <td>Coma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>table_1</td>\n",
              "      <td>employees</td>\n",
              "      <td>disfold_dataset.jsonl</td>\n",
              "      <td>employees</td>\n",
              "      <td>0.849294</td>\n",
              "      <td>Coma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>table_1</td>\n",
              "      <td>founded</td>\n",
              "      <td>disfold_dataset.jsonl</td>\n",
              "      <td>founded</td>\n",
              "      <td>0.844650</td>\n",
              "      <td>Coma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>table_1</td>\n",
              "      <td>name</td>\n",
              "      <td>disfold_dataset.jsonl</td>\n",
              "      <td>name</td>\n",
              "      <td>0.835197</td>\n",
              "      <td>Coma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>table_1</td>\n",
              "      <td>ceo</td>\n",
              "      <td>disfold_dataset.jsonl</td>\n",
              "      <td>ceo</td>\n",
              "      <td>0.831076</td>\n",
              "      <td>Coma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>table_1</td>\n",
              "      <td>headquarters</td>\n",
              "      <td>disfold_dataset.jsonl</td>\n",
              "      <td>headquarters_country</td>\n",
              "      <td>0.635563</td>\n",
              "      <td>Coma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>table_1</td>\n",
              "      <td>industry</td>\n",
              "      <td>hitHorizons_dataset.jsonl</td>\n",
              "      <td>industry</td>\n",
              "      <td>0.800279</td>\n",
              "      <td>Coma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>table_1</td>\n",
              "      <td>address</td>\n",
              "      <td>hitHorizons_dataset.jsonl</td>\n",
              "      <td>address</td>\n",
              "      <td>0.797828</td>\n",
              "      <td>Coma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>table_1</td>\n",
              "      <td>name</td>\n",
              "      <td>hitHorizons_dataset.jsonl</td>\n",
              "      <td>name</td>\n",
              "      <td>0.788374</td>\n",
              "      <td>Coma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>table_1</td>\n",
              "      <td>founded</td>\n",
              "      <td>hitHorizons_dataset.jsonl</td>\n",
              "      <td>id</td>\n",
              "      <td>0.295969</td>\n",
              "      <td>Coma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>table_1</td>\n",
              "      <td>earnings</td>\n",
              "      <td>hitHorizons_dataset.jsonl</td>\n",
              "      <td>sic_code</td>\n",
              "      <td>0.275279</td>\n",
              "      <td>Coma</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       tab1         attr1                       tab2                 attr2  \\\n",
              "0   table_1    market_cap      disfold_dataset.jsonl            market_cap   \n",
              "1   table_1     employees      disfold_dataset.jsonl             employees   \n",
              "2   table_1       founded      disfold_dataset.jsonl               founded   \n",
              "3   table_1          name      disfold_dataset.jsonl                  name   \n",
              "4   table_1           ceo      disfold_dataset.jsonl                   ceo   \n",
              "5   table_1  headquarters      disfold_dataset.jsonl  headquarters_country   \n",
              "6   table_1      industry  hitHorizons_dataset.jsonl              industry   \n",
              "7   table_1       address  hitHorizons_dataset.jsonl               address   \n",
              "8   table_1          name  hitHorizons_dataset.jsonl                  name   \n",
              "9   table_1       founded  hitHorizons_dataset.jsonl                    id   \n",
              "10  table_1      earnings  hitHorizons_dataset.jsonl              sic_code   \n",
              "\n",
              "        prob matcher  \n",
              "0   0.851268    Coma  \n",
              "1   0.849294    Coma  \n",
              "2   0.844650    Coma  \n",
              "3   0.835197    Coma  \n",
              "4   0.831076    Coma  \n",
              "5   0.635563    Coma  \n",
              "6   0.800279    Coma  \n",
              "7   0.797828    Coma  \n",
              "8   0.788374    Coma  \n",
              "9   0.295969    Coma  \n",
              "10  0.275279    Coma  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "#formati json, csv, xls, xlsx, jsonl\n",
        "df1 = pd.DataFrame(columns = ['name' , 'industry', 'market_cap', 'employees', 'country', 'headquarters', 'address', 'sector', 'ceo', 'founded', 'share_price', 'website', 'stock', 'area_served', 'earnings'])\n",
        "# df_confronto = creation_dataset_confronto(df1)\n",
        "df_confronto = pd.read_json('schema_mediato_confronto.json')\n",
        "df_logmachers = pd.DataFrame(columns = ['tab1' , 'attr1', 'tab2', 'attr2', 'prob', 'matcher'])\n",
        "\n",
        "#numero di errori nell'esecuzione di file\n",
        "num_error = 0\n",
        "\n",
        "directory = 'datasets'\n",
        "dataset_list_json = Path(directory).glob('*.json')\n",
        "dataset_list_jsonl = Path(directory).glob('*.jsonl')\n",
        "dataset_list_csv = Path(directory).glob('*.csv')\n",
        "dataset_list_xls = Path(directory).glob('*.xls')\n",
        "dataset_list_xlsx = Path(directory).glob('*.xlsx')\n",
        "i = 0\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# Modificare seleziona_tipo per scegliere che tipo di file eseguire\n",
        "# --------------------------------------------------------------------\n",
        "seleziona_tipo = 2\n",
        "\n",
        "# CON SELEZIONA_TIPO=0 SI RUNNANO I TUTTI TIPI DI FILE\n",
        "# CON SELEZIONA_TIPO=1 SI RUNNANO I JSON\n",
        "if seleziona_tipo==0 or seleziona_tipo==1:\n",
        "  for path in dataset_list_json:\n",
        "    print(str(i) + \" \" + str(path))\n",
        "    i = i+1\n",
        "    df2 = pd.read_json(path)\n",
        "    name_dataset = str(path).split('\\\\')[1]\n",
        "    try:\n",
        "      df1, df_logmachers = creation_schema_alignment(df1, df2, df_confronto, df_logmachers, name_dataset)\n",
        "    except:\n",
        "      print(\"ERRORE \" + str(path))\n",
        "      num_error = num_error + 1\n",
        "\n",
        "\n",
        "# CON SELEZIONA_TIPO=2 SI RUNNANO I JSONL\n",
        "if seleziona_tipo==0 or seleziona_tipo==2:\n",
        "  for path in dataset_list_jsonl:\n",
        "    print(str(i) + \" \" + str(path))\n",
        "    i = i+1\n",
        "    df2 = pd.read_json(path, lines=True)\n",
        "    name_dataset = str(path).split('\\\\')[1]\n",
        "    print(name_dataset)\n",
        "    try:\n",
        "      df1, df_logmachers = creation_schema_alignment(df1, df2, df_confronto, df_logmachers, name_dataset)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      print(\"ERRORE \" + str(path))\n",
        "      num_error = num_error + 1\n",
        "\n",
        "\n",
        "# CON SELEZIONA_TIPO=3 SI RUNNANO I CSV\n",
        "if seleziona_tipo==0 or seleziona_tipo==3:\n",
        "  for path in dataset_list_csv:\n",
        "    print(str(i) + \" \" + str(path))\n",
        "    i = i+1\n",
        "    df2 = pd.read_csv(path)\n",
        "    name_dataset = str(path).split('\\\\')[1]\n",
        "    try:\n",
        "      df1, df_logmachers = creation_schema_alignment(df1, df2, df_confronto, df_logmachers, name_dataset)\n",
        "    except:\n",
        "      print(\"ERRORE \" + str(path))\n",
        "      num_error = num_error + 1\n",
        "\n",
        "\n",
        "# CON SELEZIONA_TIPO=4 SI RUNNANO I XLS\n",
        "if seleziona_tipo==0 or seleziona_tipo==4:\n",
        "  for path in dataset_list_xls:\n",
        "    print(str(i) + \" \" + str(path))\n",
        "    i = i+1\n",
        "    df2 = pd.read_excel(path)\n",
        "    name_dataset = str(path).split('\\\\')[1]\n",
        "    try:\n",
        "      df1, df_logmachers = creation_schema_alignment(df1, df2, df_confronto, df_logmachers, name_dataset)\n",
        "    except:\n",
        "      print(\"ERRORE \" + str(path))\n",
        "      num_error = num_error + 1\n",
        "\n",
        "\n",
        "# CON SELEZIONA_TIPO=5 SI RUNNANO I XLSX\n",
        "if seleziona_tipo==0 or seleziona_tipo==5:\n",
        "  for path in dataset_list_xlsx:\n",
        "    print(str(i) + \" \" + str(path))\n",
        "    i = i+1\n",
        "    df2 = pd.read_excel(path)\n",
        "    name_dataset = str(path).split('\\\\')[1]\n",
        "    try:\n",
        "      df1, df_logmachers = creation_schema_alignment(df1, df2, df_confronto, df_logmachers, name_dataset)\n",
        "    except:\n",
        "      print(\"ERRORE \" + str(path))\n",
        "      num_error = num_error + 1\n",
        "\n",
        "\n",
        "print(\"Numero errori: \" + str(num_error))\n",
        "display(df1)\n",
        "print('--------DATAFRAME LOG MATCHERS--------')\n",
        "display(df_logmachers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Lg85gSJtG4Uh"
      },
      "outputs": [],
      "source": [
        "df1.to_csv('schema_mediato.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "JTP0l8H-EvgS"
      },
      "outputs": [],
      "source": [
        "df_logmachers.to_csv('log_matchers.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL2LIvxdu771"
      },
      "source": [
        "# Il codice sottostante Ã¨ utilizzato per generare il dataframe di un singolo dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "lT2NskzbXLcb",
        "outputId": "294b8c3e-c898-4ea8-c02f-b8eebf6e218f"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "unhashable type: 'list'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39m# df2 = pd.read_json('datasets/output_globaldata.json')\u001b[39;00m\n\u001b[0;32m      7\u001b[0m df2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_json(\u001b[39m'\u001b[39m\u001b[39mprova.json\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m df1, df_logmachers \u001b[39m=\u001b[39m creation_schema_alignment(df1, df2, df_confronto, df_logmachers, \u001b[39m'\u001b[39;49m\u001b[39mprova.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     10\u001b[0m df1\n\u001b[0;32m     11\u001b[0m df_logmachers\n",
            "Cell \u001b[1;32mIn[12], line 22\u001b[0m, in \u001b[0;36mcreation_schema_alignment\u001b[1;34m(df1, df2, df_confronto, df_logmachers, name_dataset)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m distr_run:\n\u001b[0;32m     21\u001b[0m   matcher_distr \u001b[39m=\u001b[39m DistributionBased(\u001b[39m0.9\u001b[39m, \u001b[39m0.9\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m   matches_distr \u001b[39m=\u001b[39m valentine_match(df_confronto, df2, matcher_distr)\n\u001b[0;32m     23\u001b[0m   distr_run \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\valentine\\__init__.py:20\u001b[0m, in \u001b[0;36mvalentine_match\u001b[1;34m(df1, df2, matcher, df1_name, df2_name)\u001b[0m\n\u001b[0;32m     18\u001b[0m     table_1 \u001b[39m=\u001b[39m valentine\u001b[39m.\u001b[39mdata_sources\u001b[39m.\u001b[39mDataframeTable(df1, name\u001b[39m=\u001b[39mdf1_name)\n\u001b[0;32m     19\u001b[0m     table_2 \u001b[39m=\u001b[39m valentine\u001b[39m.\u001b[39mdata_sources\u001b[39m.\u001b[39mDataframeTable(df2, name\u001b[39m=\u001b[39mdf2_name)\n\u001b[1;32m---> 20\u001b[0m     matches \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39msorted\u001b[39m(matcher\u001b[39m.\u001b[39;49mget_matches(table_1, table_2)\u001b[39m.\u001b[39mitems(),\n\u001b[0;32m     21\u001b[0m                           key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m item: item[\u001b[39m1\u001b[39m], reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[0;32m     22\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     23\u001b[0m     \u001b[39mraise\u001b[39;00m NotAValentineMatcher(\u001b[39m'\u001b[39m\u001b[39mThe method that you selected is not supported by Valentine\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\valentine\\algorithms\\distribution_based\\distribution_based.py:85\u001b[0m, in \u001b[0;36mDistributionBased.get_matches\u001b[1;34m(self, source_input, target_input)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m table\u001b[39m.\u001b[39mget_columns():\n\u001b[0;32m     84\u001b[0m         data\u001b[39m.\u001b[39mextend(column\u001b[39m.\u001b[39mdata)\n\u001b[1;32m---> 85\u001b[0m generate_global_ranks(data, tmp_folder_path)\n\u001b[0;32m     86\u001b[0m \u001b[39mdel\u001b[39;00m data\n\u001b[0;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__process_num \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\valentine\\algorithms\\distribution_based\\clustering_utils.py:254\u001b[0m, in \u001b[0;36mgenerate_global_ranks\u001b[1;34m(data, tmp_folder_path)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_global_ranks\u001b[39m(data: \u001b[39mlist\u001b[39m, tmp_folder_path: \u001b[39mstr\u001b[39m):\n\u001b[0;32m    244\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[39m    Function that creates a pickle file with the global ranks of all the values inside the database.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[39m        The path of the temporary folder that will serve as a cache for the run\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 254\u001b[0m     ranks \u001b[39m=\u001b[39m unix_sort_ranks(\u001b[39mset\u001b[39;49m(data), tmp_folder_path)\n\u001b[0;32m    255\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(tmp_folder_path, \u001b[39m'\u001b[39m\u001b[39mranks.pkl\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m output:\n\u001b[0;32m    256\u001b[0m         pickle\u001b[39m.\u001b[39mdump(ranks, output, pickle\u001b[39m.\u001b[39mHIGHEST_PROTOCOL)\n",
            "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
          ]
        }
      ],
      "source": [
        "df1 = pd.DataFrame(columns = ['name' , 'industry', 'market_cap', 'employees', 'country', 'headquarters', 'address', 'sector', 'ceo', 'founded', 'share_price', 'website', 'stock', 'area_served', 'revenue'])\n",
        "df_confronto = pd.read_json('schema_mediato_confronto.json')\n",
        "df_logmachers = pd.DataFrame(columns = ['tab1' , 'attr1', 'tab2', 'attr2', 'prob', 'matcher'])\n",
        "\n",
        "\n",
        "# df2 = pd.read_json('datasets/output_globaldata.json')\n",
        "df2 = pd.read_json('prova.json')\n",
        "df1, df_logmachers = creation_schema_alignment(df1, df2, df_confronto, df_logmachers, 'prova.json')\n",
        "\n",
        "df1\n",
        "df_logmachers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "d6130dc0ca154d48d4309febcf6869dce2f08df7913a461d2bad8c19ec3dd616"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

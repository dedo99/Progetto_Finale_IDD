{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record linkage con Python Record Linkage Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import recordlinkage\n",
    "import pandas as pd\n",
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulizia dei dati e modifica campi in maiuscolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCompleteDataset(path = 'output_alignment_multithread_finalpass/schema_mediato.json'):\n",
    "    #schema mediato finale di schema alignment\n",
    "    df = pd.read_json(path)\n",
    "\n",
    "    df = df[df.name.isnull() == False]\n",
    "\n",
    "    df['name'] = df['name'].replace(r'\\s+|\\\\n|\\\\r', ' ', regex=True)\n",
    "    df['name'] = df['name'].str.upper()\n",
    "    df['industry'] = df['industry'].str.upper()\n",
    "    df['country'] = df['country'].str.upper()\n",
    "    df['headquarters'] = df['headquarters'].str.upper()\n",
    "    df['address'] = df['address'].str.upper()\n",
    "    df['sector'] = df['sector'].str.upper()\n",
    "    df['ceo'] = df['ceo'].str.upper()\n",
    "    df['founders'] = df['founders'].str.upper()\n",
    "    df['area_served'] = df['area_served'].str.upper()\n",
    "\n",
    "    return df\n",
    "\n",
    "df=getCompleteDataset()\n",
    "\n",
    "df_a = df\n",
    "df_b = df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking sul name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(field, df_a, df_b):\n",
    "    indexer = recordlinkage.Index()\n",
    "    indexer.block(field)\n",
    "    return indexer.index(df_a, df_b)\n",
    "candidate_links = block('name', df_a, df_b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminare coppie uguali e speculari, ad esempio, (A,A) o in casi in cui (A,B) e (B,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match trovati senza copie: 559960\n"
     ]
    }
   ],
   "source": [
    "def getMultiIndexNoCopy(candidate_links):\n",
    "    # eliminazione coppie indici uguali, sx-dx = dx-sx\n",
    "    set_no_copy = set()\n",
    "    for (c,b) in candidate_links:\n",
    "        if (b,c) not in set_no_copy and (c != b):\n",
    "            set_no_copy.add((c,b))\n",
    "\n",
    "    print(\"Match trovati senza copie: \" + str(len(set_no_copy)))\n",
    "\n",
    "    list_no_copy = list(set_no_copy)\n",
    "    # gli elementi delle coppie vengono distribuite su due liste parallele\n",
    "    list_0 = [x[0] for x in list_no_copy] #indici sinistri\n",
    "    list_1 = [x[1] for x in list_no_copy] #indici destri\n",
    "\n",
    "    return pd.MultiIndex.from_arrays([list_0, list_1])\n",
    "multi_index = getMultiIndexNoCopy(candidate_links)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record linkage su (name, name), (country, country), (headquarters, country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = recordlinkage.Compare()\n",
    "\n",
    "compare.string('name', 'name', method='jarowinkler', threshold=0.7)\n",
    "# compare.string('industry', 'industry', method='jarowinkler', threshold=0.85)\n",
    "compare.string('country', 'country', method='jarowinkler', threshold=0.5, missing_value=1)\n",
    "compare.string('headquarters', 'country', method='jarowinkler', threshold=0.5, missing_value=1)\n",
    "# compare.string('country', 'headquarters', method='jarowinkler', threshold=0.5)\n",
    "# compare.string('headquarters', 'headquarters', method='jarowinkler', threshold=0.5)\n",
    "\n",
    "\n",
    "# compare.string('headquarters', 'headquarters', method='jarowinkler', threshold=0.85)\n",
    "# compare.string('ceo', 'ceo', method='jarowinkler', threshold=0.85)\n",
    "# compare.string('sector', 'sector', method='jarowinkler', threshold=0.85)\n",
    "\n",
    "# The comparison vectors\n",
    "compare_vectors = compare.compute(candidate_links, df_a, df_b)\n",
    "# pulizia dalle coppie in eccesso\n",
    "compare_vectors = compare_vectors[compare_vectors.index.isin(multi_index)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predizione Record Linkage con ECM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecmFitPredict(compare_vectors):\n",
    "    ecm = recordlinkage.ECMClassifier()\n",
    "    return ecm.fit_predict(compare_vectors)\n",
    "matches = ecmFitPredict(compare_vectors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creazione di un dizionario con chiave che corrispondono a record relativi ad una entità e come valore una lista di entità che corrispondono a quella relativa alla chiave associata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDictMatches(matches):\n",
    "    dict_matches = {}\n",
    "    keyToIgnore = set()\n",
    "    for k, v in matches:\n",
    "        if k in keyToIgnore:\n",
    "            continue\n",
    "        elif k in dict_matches.keys():\n",
    "            dict_matches[k].append(v)\n",
    "            keyToIgnore.add(v)\n",
    "        else :\n",
    "            dict_matches[k] = [v]\n",
    "            keyToIgnore.add(v)\n",
    "    return dict_matches\n",
    "\n",
    "dict_matches_global = getDictMatches(matches)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vengono collassati i record relativi alla stessa entità in un unico record combinando i valori degli attributi di tutti i record della stessa entità (il valore di ogni attributo di un record collassato corrisponde al primo individuato con valore diverso dal None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m         df_collapsed\u001b[39m.\u001b[39mloc[\u001b[39mlen\u001b[39m(df_collapsed\u001b[39m.\u001b[39mindex)]\u001b[39m=\u001b[39mrow\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m]\n\u001b[0;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m df_collapsed, indexesToDelete\n\u001b[1;32m---> 16\u001b[0m df_collapsed_prima, indexesToDeleteGlobal \u001b[39m=\u001b[39m collapseMatches(getCompleteDataset(), dict_matches_global)\n\u001b[0;32m     17\u001b[0m df_collapsed_prima\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39moutput_integration/matches_collapsed.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn [8], line 11\u001b[0m, in \u001b[0;36mcollapseMatches\u001b[1;34m(df, dict_matches)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[39mfor\u001b[39;00m field \u001b[39min\u001b[39;00m row:\n\u001b[0;32m     10\u001b[0m         \u001b[39mif\u001b[39;00m(row[field]\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39many()):\n\u001b[1;32m---> 11\u001b[0m             \u001b[39mif\u001b[39;00m(\u001b[39mnot\u001b[39;00m df[df\u001b[39m.\u001b[39;49mindex \u001b[39m==\u001b[39;49m v][field]\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39many()):\n\u001b[0;32m     12\u001b[0m                 row\u001b[39m.\u001b[39mat[k, field] \u001b[39m=\u001b[39m df[df\u001b[39m.\u001b[39mindex\u001b[39m==\u001b[39mv][field]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m]\n\u001b[0;32m     13\u001b[0m df_collapsed\u001b[39m.\u001b[39mloc[\u001b[39mlen\u001b[39m(df_collapsed\u001b[39m.\u001b[39mindex)]\u001b[39m=\u001b[39mrow\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\feder\\anaconda3\\envs\\bert\\lib\\site-packages\\pandas\\core\\ops\\common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m     70\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 72\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32mc:\\Users\\feder\\anaconda3\\envs\\bert\\lib\\site-packages\\pandas\\core\\arraylike.py:42\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__eq__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__eq__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmp_method(other, operator\u001b[39m.\u001b[39;49meq)\n",
      "File \u001b[1;32mc:\\Users\\feder\\anaconda3\\envs\\bert\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6984\u001b[0m, in \u001b[0;36mIndex._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6982\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6983\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 6984\u001b[0m         result \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mcomparison_op(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, other, op)\n\u001b[0;32m   6986\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\feder\\anaconda3\\envs\\bert\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:290\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    287\u001b[0m     res_values \u001b[39m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[0;32m    289\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 290\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    292\u001b[0m \u001b[39mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mc:\\Users\\feder\\anaconda3\\envs\\bert\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:165\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    162\u001b[0m     func \u001b[39m=\u001b[39m partial(expressions\u001b[39m.\u001b[39mevaluate, op)\n\u001b[0;32m    164\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 165\u001b[0m     result \u001b[39m=\u001b[39m func(left, right)\n\u001b[0;32m    166\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_cmp \u001b[39mand\u001b[39;00m (is_object_dtype(left\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(right)):\n\u001b[0;32m    168\u001b[0m         \u001b[39m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[0;32m    169\u001b[0m         \u001b[39m#  on the non-missing values)\u001b[39;00m\n\u001b[0;32m    170\u001b[0m         \u001b[39m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    171\u001b[0m         \u001b[39m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\feder\\anaconda3\\envs\\bert\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:241\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m op_str \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     \u001b[39mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    240\u001b[0m         \u001b[39m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m         \u001b[39mreturn\u001b[39;00m _evaluate(op, op_str, a, b)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[39mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32mc:\\Users\\feder\\anaconda3\\envs\\bert\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:70\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39mif\u001b[39;00m _TEST_MODE:\n\u001b[0;32m     69\u001b[0m     _store_test_result(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m op(a, b)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def collapseMatches(df, dict_matches):\n",
    "    df_collapsed = pd.DataFrame(columns=['name' , 'industry', 'market_cap', 'employees', 'country', 'headquarters', 'address', 'sector', 'ceo', 'founded', 'founders', 'share_price', 'website', 'stock', 'area_served', 'revenue'])\n",
    "    indexesToDelete = []\n",
    "    for k in dict_matches.keys():\n",
    "        indexesToDelete.append(k)\n",
    "        row = df[df.index == k]\n",
    "        for v in dict_matches[k]:\n",
    "            indexesToDelete.append(v)\n",
    "            for field in row:\n",
    "                if(row[field].isnull().values.any()):\n",
    "                    if(not df[df.index == v][field].isnull().values.any()):\n",
    "                        row.at[k, field] = df[df.index==v][field].values[0]\n",
    "        df_collapsed.loc[len(df_collapsed.index)]=row.values[0]\n",
    "    return df_collapsed, indexesToDelete\n",
    "\n",
    "df_collapsed_prima, indexesToDeleteGlobal = collapseMatches(getCompleteDataset(), dict_matches_global)\n",
    "print('Tempo trascorso: '+ str(time.time() - start))\n",
    "df_collapsed_prima.to_csv('output_integration/matches_collapsed.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seconda passata di matching\n",
    "#### criteri: matching 1:1 su name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questo dataset è già normalizzato\n",
    "df_collapsed_prima = pd.read_csv('output_integration/matches_collapsed.csv')\n",
    "\n",
    "# rimozione punti\n",
    "df_collapsed_prima['name'] = df_collapsed_prima['name'].replace(r'\\.', '', regex=True)\n",
    "\n",
    "df_collapsed_prima_a = df_collapsed_prima\n",
    "df_collapsed_prima_b = df_collapsed_prima\n",
    "\n",
    "candidate_links = block('name', df_collapsed_prima_a, df_collapsed_prima_b)\n",
    "multi_index = getMultiIndexNoCopy(candidate_links)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record Linkage solo su (name, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = recordlinkage.Compare()\n",
    "\n",
    "compare.string('name', 'name', method='jarowinkler', threshold=1)\n",
    "# workaround\n",
    "compare.string('country', 'country', method='jarowinkler', threshold=0)\n",
    "\n",
    "# The comparison vectors\n",
    "compare_vectors = compare.compute(candidate_links, df_collapsed_prima_a, df_collapsed_prima_b)\n",
    "compare_vectors = compare_vectors[compare_vectors.index.isin(multi_index)]\n",
    "\n",
    "matches = ecmFitPredict(compare_vectors)\n",
    "\n",
    "dict_matches = getDictMatches(matches)\n",
    "\n",
    "df_collapsed_seconda, indexesToDelete_seconda = collapseMatches(df_collapsed_prima, dict_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_integrato_clean = df_collapsed_prima.drop(indexesToDelete_seconda)\n",
    "df_collapsed_seconda = pd.concat([df_integrato_clean, df_collapsed_seconda], ignore_index=True)\n",
    "print('Tempo trascorso: '+ str(time.time() - start))\n",
    "df_collapsed_seconda.to_csv('output_integration/matches_collapsed_seconda.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo finale integration\n",
    "\n",
    "### eliminazione righe 'doppione'\n",
    "### concatenazione dataframe integrato dei match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = getCompleteDataset()\n",
    "df_collapsed_seconda = pd.read_csv('output_integration/matches_collapsed_seconda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(indexesToDeleteGlobal)\n",
    "df_final = pd.concat([df_clean, df_collapsed_seconda], ignore_index=True)\n",
    "print('Tempo trascorso: '+ str(time.time() - start))\n",
    "df_final.to_csv('output_integration/final_integration.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e507f021528ee598d4189b61a0c3eda1bdaecd993998d2871a13eaf733316a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

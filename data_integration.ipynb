{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record linkage con Python Record Linkage Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import recordlinkage\n",
    "import pandas as pd\n",
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulizia dei dati e modifica campi in maiuscolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCompleteDataset(path = 'output_alignment_multithread_finalpass/schema_mediato.json'):\n",
    "    #schema mediato finale di schema alignment\n",
    "    df = pd.read_json(path)\n",
    "\n",
    "    df = df[df.name.isnull() == False]\n",
    "\n",
    "    df['name'] = df['name'].replace(r'\\s+|\\\\n|\\\\r', ' ', regex=True)\n",
    "    df['name'] = df['name'].str.upper()\n",
    "    df['industry'] = df['industry'].str.upper()\n",
    "    df['country'] = df['country'].str.upper()\n",
    "    df['headquarters'] = df['headquarters'].str.upper()\n",
    "    df['address'] = df['address'].str.upper()\n",
    "    df['sector'] = df['sector'].str.upper()\n",
    "    df['ceo'] = df['ceo'].str.upper()\n",
    "    df['founders'] = df['founders'].str.upper()\n",
    "    df['area_served'] = df['area_served'].str.upper()\n",
    "\n",
    "    return df\n",
    "\n",
    "df=getCompleteDataset()\n",
    "\n",
    "df_a = df\n",
    "df_b = df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking sul name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(field, df_a, df_b):\n",
    "    indexer = recordlinkage.Index()\n",
    "    indexer.block(field)\n",
    "    return indexer.index(df_a, df_b)\n",
    "candidate_links = block('name', df_a, df_b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminare coppie uguali e speculari, ad esempio, (A,A) o in casi in cui (A,B) e (B,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMultiIndexNoCopy(candidate_links):\n",
    "    # eliminazione coppie indici uguali, sx-dx = dx-sx\n",
    "    set_no_copy = set()\n",
    "    for (c,b) in candidate_links:\n",
    "        if (b,c) not in set_no_copy and (c != b):\n",
    "            set_no_copy.add((c,b))\n",
    "\n",
    "    print(\"Match trovati senza copie: \" + str(len(set_no_copy)))\n",
    "\n",
    "    list_no_copy = list(set_no_copy)\n",
    "    # gli elementi delle coppie vengono distribuite su due liste parallele\n",
    "    list_0 = [x[0] for x in list_no_copy] #indici sinistri\n",
    "    list_1 = [x[1] for x in list_no_copy] #indici destri\n",
    "\n",
    "    return pd.MultiIndex.from_arrays([list_0, list_1])\n",
    "multi_index = getMultiIndexNoCopy(candidate_links)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record linkage su (name, name), (country, country), (headquarters, country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = recordlinkage.Compare()\n",
    "\n",
    "compare.string('name', 'name', method='jarowinkler', threshold=0.7)\n",
    "# compare.string('industry', 'industry', method='jarowinkler', threshold=0.85)\n",
    "compare.string('country', 'country', method='jarowinkler', threshold=0.5, missing_value=1)\n",
    "compare.string('headquarters', 'country', method='jarowinkler', threshold=0.5, missing_value=1)\n",
    "# compare.string('country', 'headquarters', method='jarowinkler', threshold=0.5)\n",
    "# compare.string('headquarters', 'headquarters', method='jarowinkler', threshold=0.5)\n",
    "\n",
    "\n",
    "# compare.string('headquarters', 'headquarters', method='jarowinkler', threshold=0.85)\n",
    "# compare.string('ceo', 'ceo', method='jarowinkler', threshold=0.85)\n",
    "# compare.string('sector', 'sector', method='jarowinkler', threshold=0.85)\n",
    "\n",
    "# The comparison vectors\n",
    "compare_vectors = compare.compute(candidate_links, df_a, df_b)\n",
    "# pulizia dalle coppie in eccesso\n",
    "compare_vectors = compare_vectors[compare_vectors.index.isin(multi_index)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predizione Record Linkage con ECM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecmFitPredict(compare_vectors):\n",
    "    ecm = recordlinkage.ECMClassifier()\n",
    "    return ecm.fit_predict(compare_vectors)\n",
    "matches = ecmFitPredict(compare_vectors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creazione di un dizionario con chiave che corrispondono a record relativi ad una entità e come valore una lista di entità che corrispondono a quella relativa alla chiave associata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDictMatches(matches):\n",
    "    dict_matches = {}\n",
    "    keyToIgnore = set()\n",
    "    for k, v in matches:\n",
    "        if k in keyToIgnore:\n",
    "            continue\n",
    "        elif k in dict_matches.keys():\n",
    "            dict_matches[k].append(v)\n",
    "            keyToIgnore.add(v)\n",
    "        else :\n",
    "            dict_matches[k] = [v]\n",
    "            keyToIgnore.add(v)\n",
    "    return dict_matches\n",
    "\n",
    "dict_matches_global = getDictMatches(matches)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vengono collassati i record relativi alla stessa entità in un unico record combinando i valori degli attributi di tutti i record della stessa entità (il valore di ogni attributo di un record collassato corrisponde al primo individuato con valore diverso dal None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collapseMatches(df, dict_matches):\n",
    "    df_collapsed = pd.DataFrame(columns=['name' , 'industry', 'market_cap', 'employees', 'country', 'headquarters', 'address', 'sector', 'ceo', 'founded', 'founders', 'share_price', 'website', 'stock', 'area_served', 'revenue'])\n",
    "    indexesToDelete = []\n",
    "    for k in dict_matches.keys():\n",
    "        indexesToDelete.append(k)\n",
    "        row = df[df.index == k]\n",
    "        for v in dict_matches[k]:\n",
    "            indexesToDelete.append(v)\n",
    "            for field in row:\n",
    "                if(row[field].isnull().values.any()):\n",
    "                    if(not df[df.index == v][field].isnull().values.any()):\n",
    "                        row.at[k, field] = df[df.index==v][field].values[0]\n",
    "        df_collapsed.loc[len(df_collapsed.index)]=row.values[0]\n",
    "    return df_collapsed, indexesToDelete\n",
    "\n",
    "df_collapsed_prima, indexesToDeleteGlobal = collapseMatches(getCompleteDataset(), dict_matches_global)\n",
    "print('Tempo trascorso: '+ str(time.time() - start))\n",
    "df_collapsed_prima.to_csv('output_integration/matches_collapsed.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seconda passata di matching\n",
    "#### criteri: matching 1:1 su name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questo dataset è già normalizzato\n",
    "df_collapsed_prima = pd.read_csv('output_integration/matches_collapsed.csv')\n",
    "\n",
    "# rimozione punti\n",
    "df_collapsed_prima['name'] = df_collapsed_prima['name'].replace(r'\\.', '', regex=True)\n",
    "\n",
    "df_collapsed_prima_a = df_collapsed_prima\n",
    "df_collapsed_prima_b = df_collapsed_prima\n",
    "\n",
    "candidate_links = block('name', df_collapsed_prima_a, df_collapsed_prima_b)\n",
    "multi_index = getMultiIndexNoCopy(candidate_links)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record Linkage solo su (name, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = recordlinkage.Compare()\n",
    "\n",
    "compare.string('name', 'name', method='jarowinkler', threshold=1)\n",
    "# workaround\n",
    "compare.string('country', 'country', method='jarowinkler', threshold=0)\n",
    "\n",
    "# The comparison vectors\n",
    "compare_vectors = compare.compute(candidate_links, df_collapsed_prima_a, df_collapsed_prima_b)\n",
    "compare_vectors = compare_vectors[compare_vectors.index.isin(multi_index)]\n",
    "\n",
    "matches = ecmFitPredict(compare_vectors)\n",
    "\n",
    "dict_matches = getDictMatches(matches)\n",
    "\n",
    "df_collapsed_seconda, indexesToDelete_seconda = collapseMatches(df_collapsed_prima, dict_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_integrato_clean = df_collapsed_prima.drop(indexesToDelete_seconda)\n",
    "df_collapsed_seconda = pd.concat([df_integrato_clean, df_collapsed_seconda], ignore_index=True)\n",
    "print('Tempo trascorso: '+ str(time.time() - start))\n",
    "df_collapsed_seconda.to_csv('output_integration/matches_collapsed_seconda.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo finale integration\n",
    "\n",
    "### eliminazione righe 'doppione'\n",
    "### concatenazione dataframe integrato dei match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = getCompleteDataset()\n",
    "df_collapsed_seconda = pd.read_csv('output_integration/matches_collapsed_seconda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(indexesToDeleteGlobal)\n",
    "df_final = pd.concat([df_clean, df_collapsed_seconda], ignore_index=True)\n",
    "print('Tempo trascorso: '+ str(time.time() - start))\n",
    "df_final.to_csv('output_integration/final_integration.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e507f021528ee598d4189b61a0c3eda1bdaecd993998d2871a13eaf733316a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
